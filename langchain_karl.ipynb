{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNc/foDqlE9+JM1v0v4dxGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacksonkarel/etl-langchain/blob/main/langchain_karl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAgfE8uJ5mf0",
        "outputId": "1effc92a-532a-4dbe-e502-d64a3ce1840b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.8/dist-packages (0.0.94)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.4.46)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.8/dist-packages (from langchain) (2.28.2)\n",
            "Requirement already satisfied: aleph-alpha-client<3.0.0,>=2.15.0 in /usr/local/lib/python3.8/dist-packages (from langchain) (2.16.0)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.8/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from langchain) (8.2.1)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.8/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.10.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.8/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.8/dist-packages (from aleph-alpha-client<3.0.0,>=2.15.0->langchain) (0.13.2)\n",
            "Requirement already satisfied: aiodns>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from aleph-alpha-client<3.0.0,>=2.15.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: aiohttp-retry>=2.8.3 in /usr/local/lib/python3.8/dist-packages (from aleph-alpha-client<3.0.0,>=2.15.0->langchain) (2.8.3)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.8/dist-packages (from aleph-alpha-client<3.0.0,>=2.15.0->langchain) (1.26.14)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from aiodns>=3.0.0->aleph-alpha-client<3.0.0,>=2.15.0->langchain) (4.3.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pycares>=4.0.0->aiodns>=3.0.0->aleph-alpha-client<3.0.0,>=2.15.0->langchain) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns>=3.0.0->aleph-alpha-client<3.0.0,>=2.15.0->langchain) (2.21)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.8/dist-packages (0.26.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.28.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.8/dist-packages (2.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from google-search-results) (2.28.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->google-search-results) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->google-search-results) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->google-search-results) (3.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->google-search-results) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "keys = json.load(open('keys.json'))\n",
        "os.environ[\"OPENAI_API_KEY\"] = keys['openai']\n",
        "os.environ[\"SERPAPI_API_KEY\"] = keys['serp']\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_cOQsfaL5vim"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain import OpenAI\n",
        "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
        "from langchain.utilities import PythonREPL\n",
        "from langchain.agents import initialize_agent"
      ],
      "metadata": {
        "id": "rQjMtHoo5vcX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python_repl = PythonREPL()\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Python REPL\",\n",
        "        func=python_repl.run,\n",
        "        description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. Always print the output of the python command.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "llm=OpenAI(temperature=0)\n",
        "agent_chain = initialize_agent(tools, llm, agent=\"conversational-react-description\", verbose=True, memory=memory)"
      ],
      "metadata": {
        "id": "QDT5ftCC8z6H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OLuGQ7PzElXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent"
      ],
      "metadata": {
        "id": "Mxtougt9TeJw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"python_repl\"], llm=llm)\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "\n",
        "input = \"\"\"Execute the following steps:\n",
        "\n",
        "1. Using python execution, load `dataset.csv`\n",
        "\n",
        "2. Using python execution, iterate over the columns of the dataset printing the column name and datatype\n",
        "\n",
        "3. Identify which columns are feature columns and which columns are label columns\n",
        "\n",
        "4. Split the dataset into features and labels\n",
        "\n",
        "5. Based on the data types, write python code for preprocessing and normalizing the features using sklearn\n",
        "\n",
        "6. Add labels back to the processed dataframe\n",
        "\n",
        "7. Save the processed data as `dataset_processed.csv`\n",
        "\"\"\"\n",
        "\n",
        "agent.run(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eFc9pIO9TeHk",
        "outputId": "32744796-dfd0-49b4-80a4-e619b186e7fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to use the Python REPL to execute the steps\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "import pandas as pd\n",
            "\n",
            "dataset = pd.read_csv('dataset.csv')\n",
            "\n",
            "for col in dataset.columns:\n",
            "    print(col, dataset[col].dtype)\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3malcohol float64\n",
            "malic_acid float64\n",
            "ash float64\n",
            "alcalinity_of_ash float64\n",
            "magnesium float64\n",
            "total_phenols float64\n",
            "flavanoids float64\n",
            "nonflavanoid_phenols float64\n",
            "proanthocyanins float64\n",
            "color_intensity float64\n",
            "hue float64\n",
            "od280/od315_of_diluted_wines float64\n",
            "proline float64\n",
            "target int64\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to identify which columns are feature columns and which columns are label columns\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "feature_columns = dataset.columns[:-1]\n",
            "label_column = dataset.columns[-1]\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to split the dataset into features and labels\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "features = dataset[feature_columns]\n",
            "labels = dataset[label_column]\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to preprocess and normalize the features using sklearn\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "from sklearn.preprocessing import StandardScaler\n",
            "\n",
            "scaler = StandardScaler()\n",
            "scaled_features = scaler.fit_transform(features)\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to add labels back to the processed dataframe\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "processed_dataset = pd.DataFrame(scaled_features, columns=feature_columns)\n",
            "processed_dataset[label_column] = labels\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to save the processed data as `dataset_processed.csv`\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "processed_dataset.to_csv('dataset_processed.csv', index=False)\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The final answer is that the dataset has been preprocessed and normalized using sklearn, and saved as `dataset_processed.csv`.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The final answer is that the dataset has been preprocessed and normalized using sklearn, and saved as `dataset_processed.csv`.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"\"\"Execute the following steps:\n",
        "\n",
        "1. Using python execution, load `dataset_processed.csv`\n",
        "\n",
        "2. Split the dataset into train and test sets\n",
        "\n",
        "3. Select a machine learning model from the sklearn library\n",
        "\n",
        "4. Fit the sklearn model to the training data\n",
        "\n",
        "5. Use the trained model to predict on the test dataset\n",
        "\n",
        "6. Evaluate the predictions using an appropriate metric. Print the result\n",
        "\n",
        "7. Save the trained model to disk\n",
        "\"\"\"\n",
        "\n",
        "agent.run(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "2YRX-CEfTeDX",
        "outputId": "5964c210-4784-4f53-c15a-0cc85f1f7f8a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to use the Python REPL to execute the steps\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "import pandas as pd\n",
            "dataset = pd.read_csv('dataset_processed.csv')\n",
            "from sklearn.model_selection import train_test_split\n",
            "X_train, X_test, y_train, y_test = train_test_split(dataset.drop('target', axis=1), dataset['target'], test_size=0.2, random_state=42)\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "model = LogisticRegression()\n",
            "model.fit(X_train, y_train)\n",
            "predictions = model.predict(X_test)\n",
            "from sklearn.metrics import accuracy_score\n",
            "accuracy = accuracy_score(y_test, predictions)\n",
            "print(accuracy)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m1.0\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to save the model to disk\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "import joblib\n",
            "joblib.dump(model, 'model.joblib')\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The model has been saved to disk as 'model.joblib'. The accuracy of the predictions is 1.0.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The model has been saved to disk as 'model.joblib'. The accuracy of the predictions is 1.0.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nwZYPr3XTd_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ETBs9T-kovT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"python_repl\"], llm=llm)\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "\n",
        "input1 = \"\"\"Execute the following steps:\n",
        "\n",
        "1. Using python execution, load `dataset.csv`\n",
        "\n",
        "3. Using python execution, split the dataset into train and test sets using a 80% random split\n",
        "\n",
        "4. Save the datasets to `train_data.csv` and `test_data.csv`\n",
        "\"\"\"\n",
        "\n",
        "input2 = \"\"\"Execute the following steps to train an sklearn model:\n",
        "\n",
        "Using python execution, load `train_data.csv`\n",
        "\n",
        "Using python execution, iterate over the columns of the dataset printing the column name and datatype\n",
        "\n",
        "Identify which columns are feature columns and which columns are label columns\n",
        "\n",
        "Split the dataset into features and labels\n",
        "\n",
        "Determine if the problem is a classification or regression problem\n",
        "\n",
        "Create an sklearn pipeline including preprocessing and modeling\n",
        "\n",
        "Fit the pipeline to the dataset\n",
        "\n",
        "Save the fitted pipeline to disk as `model.joblib`\n",
        "\"\"\"\n",
        "\n",
        "input3 = \"\"\"Execute the following steps to run inference with a sklearn model:\n",
        "\n",
        "1. Using python execution, load the sklearn model `model.joblib` from disk\n",
        "\n",
        "2. Using python execution, load `test_data.csv`\n",
        "\n",
        "3. Using python execution, iterate over the columns of the dataset printing the column name and datatype\n",
        "\n",
        "4. Split the dataset into features and labels\n",
        "\n",
        "5. Run prediction inference on the test data\n",
        "\n",
        "6. Evaluate the predictions with an appropreate metric\n",
        "\n",
        "7. Print the result\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "oK08UxA1oX0K"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(input1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "ljkCb2PltVOm",
        "outputId": "6d6fda71-7257-42b7-f7d4-bcec418b2b8a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to use the Python REPL to execute the steps\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "import pandas as pd\n",
            "data = pd.read_csv('dataset.csv')\n",
            "train_data, test_data = data.train_test_split(test_size=0.2, random_state=0)\n",
            "train_data.to_csv('train_data.csv', index=False)\n",
            "test_data.to_csv('test_data.csv', index=False)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m'DataFrame' object has no attribute 'train_test_split'\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to use the sklearn library\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "import pandas as pd\n",
            "from sklearn.model_selection import train_test_split\n",
            "data = pd.read_csv('dataset.csv')\n",
            "train_data, test_data = train_test_split(data, test_size=0.2, random_state=0)\n",
            "train_data.to_csv('train_data.csv', index=False)\n",
            "test_data.to_csv('test_data.csv', index=False)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The datasets should now be saved\n",
            "Final Answer: The datasets should now be saved to `train_data.csv` and `test_data.csv`.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The datasets should now be saved to `train_data.csv` and `test_data.csv`.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(input2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aH2E0k-3tWNX",
        "outputId": "6653a953-5ac7-4be9-d689-dbddb22e0635"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to use the Python REPL to execute the steps\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "import pandas as pd\n",
            "train_data = pd.read_csv('train_data.csv')\n",
            "for col in train_data.columns:\n",
            "    print(col, train_data[col].dtype)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3malcohol float64\n",
            "malic_acid float64\n",
            "ash float64\n",
            "alcalinity_of_ash float64\n",
            "magnesium float64\n",
            "total_phenols float64\n",
            "flavanoids float64\n",
            "nonflavanoid_phenols float64\n",
            "proanthocyanins float64\n",
            "color_intensity float64\n",
            "hue float64\n",
            "od280/od315_of_diluted_wines float64\n",
            "proline float64\n",
            "target int64\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to identify which columns are feature columns and which columns are label columns\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "features = train_data.drop('target', axis=1)\n",
            "labels = train_data['target']\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to split the dataset into features and labels\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mname 'train_test_split' is not defined\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to import the train_test_split function\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "from sklearn.model_selection import train_test_split\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to determine if the problem is a classification or regression problem\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "if len(labels.unique()) > 2:\n",
            "    print('Classification Problem')\n",
            "else:\n",
            "    print('Regression Problem')\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mClassification Problem\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to create an sklearn pipeline including preprocessing and modeling\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "from sklearn.pipeline import make_pipeline\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from sklearn.ensemble import RandomForestClassifier\n",
            "\n",
            "pipeline = make_pipeline(StandardScaler(), RandomForestClassifier())\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to fit the pipeline to the dataset\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "pipeline.fit(X_train, y_train)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mname 'X_train' is not defined\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to define X_train and y_train\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to fit the pipeline to the dataset\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "pipeline.fit(X_train, y_train)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to save the fitted pipeline to disk as `model.joblib`\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "from joblib import dump\n",
            "dump(pipeline, 'model.joblib')\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The final answer is to execute the following steps to train an sklearn model: Using python execution, load `train_data.csv`, iterate over the columns of the dataset printing the column name and datatype, identify which columns are feature columns and which columns are label columns, split the dataset into features and labels, determine if the problem is a classification or regression problem, create an sklearn pipeline including preprocessing and modeling, fit the pipeline to the dataset, and save the fitted pipeline to disk as `model.joblib`.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The final answer is to execute the following steps to train an sklearn model: Using python execution, load `train_data.csv`, iterate over the columns of the dataset printing the column name and datatype, identify which columns are feature columns and which columns are label columns, split the dataset into features and labels, determine if the problem is a classification or regression problem, create an sklearn pipeline including preprocessing and modeling, fit the pipeline to the dataset, and save the fitted pipeline to disk as `model.joblib`.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(input3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "X4Bqcv_ZuY0O",
        "outputId": "571cfc97-4abc-4981-ec22-fe87185491a1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to use the Python REPL to execute the steps\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "import joblib\n",
            "model = joblib.load('model.joblib')\n",
            "\n",
            "import pandas as pd\n",
            "test_data = pd.read_csv('test_data.csv')\n",
            "\n",
            "for col in test_data.columns:\n",
            "    print(col, test_data[col].dtype)\n",
            "\n",
            "X = test_data.drop('label', axis=1)\n",
            "y = test_data['label']\n",
            "\n",
            "predictions = model.predict(X)\n",
            "\n",
            "from sklearn.metrics import accuracy_score\n",
            "accuracy = accuracy_score(y, predictions)\n",
            "\n",
            "print(accuracy)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\"['label'] not found in axis\"\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to make sure I'm splitting the dataset correctly\n",
            "Action: Python REPL\n",
            "Action Input: \n",
            "X = test_data.drop('target', axis=1)\n",
            "y = test_data['target']\n",
            "\n",
            "predictions = model.predict(X)\n",
            "\n",
            "from sklearn.metrics import accuracy_score\n",
            "accuracy = accuracy_score(y, predictions)\n",
            "\n",
            "print(accuracy)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m0.9722222222222222\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The accuracy of the model on the test data is 0.9722222222222222.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The accuracy of the model on the test data is 0.9722222222222222.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zcIOpm48vIhd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}